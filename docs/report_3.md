# Отчет
Исследование поведения серверов Flask и Gunicorn под различными типами нагрузки.

### Метод исследования

В файле `src/utils.py` определены три функции, которые имитируют три решения задачи `predict`:
- `predict_io_bounded(area)` - соответствует второму варианту, запрос к стороннему сервису заменяется `time.sleep(1)`. Это соответствует задержке в 1 секунду, которая необходима для обмена информацией со сторонним сервисом. При этом вычислительная нагрузка на наш сервер не создается, процесс просто спит.
- `predict_cpu_bounded(area, n)` - соответствует первому варианту, предикат на своем сервере. Параметр `n` позволяет регулировать нагрузку, фактически это просто вычисление среднего арифметического линейного массива. Если `n` достаточно велик, сервер выдаст ошибку из-за нехватки памяти. Необходимо определить это значение эмпирически.
- `predict_cpu_multithread(area, n)` - также соответствует первому варианту, но используется оптимизированный код numpy. Также необходимо эмпирически определить критическое значение `n` и сравнить его с предыдущим.

Доступны два варианта запуска сервиса:
- `python src/predict_app.py` - сервер, предназначенный для разработки.
- `gunicorn src.predict_app:app` - сервер, предназначенный для постоянной работы в производстве.
* Был использован второй вариант.

Нагрузка создается файлом `test/test_parallel.py`.

### Результаты и обсуждение
1) При запуске `predict_io_bounded` на сервере gunicorn prom с мы получили [результат](https://github.com/Ezopik/pabd24/blob/main/log/gunicorn_io_bounded.txt). Все запросы обрабатываются последовательно, в среднем за 5 секунд.

2) При запуске `predict_cpu_bounded` на сервере gunicorn prom с n=90_000_000 мы получили [результат](https://github.com/Ezopik/pabd24/blob/main/log/gunicorn_cpu_bounded.txt). Все запросы обрабатываются последовательно, в среднем за 35 секунд. Сервер падает с n = 95_000_000.

3) При запуске `predict_cpu_multithread` на сервере gunicorn prom с n=420_000_000 мы получили [результат](https://github.com/Ezopik/pabd24/blob/main/log/gunicorn_cpu_multithread.txt). Все запросы обрабатываются последовательно, в среднем за 11.3 секунды. Сервер падает с n = 450_000_000.

4) При запуске `predict_io_bounded` на сервере flask dev мы получили [результат](https://github.com/Ezopik/pabd24/blob/main/log/flask_io_bounded.txt). Все запросы обрабатываются одновременно, в среднем за 1.02 секунд.
 
5) При запуске `predict_cpu_bounded` на сервере flask dev с n=9_500_000 мы получили [результат](https://github.com/Ezopik/pabd24/blob/main/log/flask_cpu_bounded.txt). Все запросы обрабатываются одновременно, в среднем за 5.6 секунд.

6) При запуске `predict_cpu_multithread` на сервере flask dev с n=47_000_000 мы получили [результат](https://github.com/Ezopik/pabd24/blob/main/log/flask_cpu_multithread.txt). Все запросы обрабатываются одновременно, в среднем за 1.3 секунд.

### Вывод
На основе результатов тестирования можно сделать следующие выводы:
- Flask подходит для разработки и тестирования, но не подходит для высокой нагрузки в производстве.
- Gunicorn показывает лучшие результаты при высокой нагрузке.